# -*- coding: utf-8 -*-
"""SD3DreamFusionCaseStudy-DEMO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jvp-rDFAbzPYUqRWwToU2aKlB85LF8BH

# Setup

Editable configuration parameters
"""

USE_SD3 = True

# Data Config
DS_NAME = "ozgung/red-bowl-5"
#DS_NAME = "ozgung/red-bowl"
#DS_NAME = "ozgung/tubik"
#DS_NAME = "ozgung/bladerunner2049"

INSTANCE_PROMPT = "a photo of sks bowl"
TEST_PROMPT = "a photo of sks bowl with grapes in it"

TRAIN_MODEL = False # Train or load finetuned from Hub

# Training params
LEARNING_RATE = 5e-6
TRAIN_STEPS = 800

MODEL_NAME = DS_NAME + ("-SD3" if USE_SD3 else "-SD")

# Install Diffusers Library and Requirements for DreamBooth
!git clone https://github.com/ozgung/diffusers

!pip install -qq ./diffusers
if USE_SD3:
  !pip install -qq -r ./diffusers/examples/dreambooth/requirements_sd3.txt
else:
  !pip install -qq -r ./diffusers/examples/dreambooth/requirements.txt

!pip install -qq bitsandbytes

import torch
from accelerate.utils import write_basic_config

write_basic_config()
assert torch.cuda.is_available(), "CUDA is not available. Consider choosing a GPU runtime."

"""## Login to HuggingFace"""

# Enter token for HuggingFace
from huggingface_hub import notebook_login
notebook_login()

"""#Prepare Data"""

from huggingface_hub import snapshot_download
import shutil, os.path

local_dir = os.path.join('./IN', MODEL_NAME)
output_dir = os.path.join("./OUT", MODEL_NAME)

snapshot_download(
    DS_NAME,
    local_dir=local_dir,
    repo_type="dataset",
    allow_patterns=["*.jpeg", "*.jpg", "*.png"],
    ignore_patterns=[".gitattributes","*.md"],
)

shutil.rmtree(os.path.join(local_dir,'.huggingface/'))

"""#Train"""

BASE_MODEL = "stabilityai/stable-diffusion-3-medium-diffusers" if USE_SD3 else "runwayml/stable-diffusion-v1-5"

if USE_SD3:
  train_cmd = f"""
accelerate launch diffusers/examples/dreambooth/train_dreambooth_sd3.py \
  --pretrained_model_name_or_path="{BASE_MODEL}"  \
  --instance_data_dir="{local_dir}" \
  --output_dir="{output_dir}" \
  --instance_prompt="{INSTANCE_PROMPT}" \
  --mixed_precision="fp16" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate={LEARNING_RATE} \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps={TRAIN_STEPS} \
  --use_8bit_adam \
  --gradient_checkpointing \
  --seed="0" \
  --push_to_hub
"""
else:
    train_cmd = f"""
accelerate launch diffusers/examples/dreambooth/train_dreambooth.py \
  --pretrained_model_name_or_path="{BASE_MODEL}"  \
  --instance_data_dir="{local_dir}" \
  --output_dir="{output_dir}" \
  --instance_prompt="{INSTANCE_PROMPT}" \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate={LEARNING_RATE} \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps={TRAIN_STEPS} \
  --gradient_checkpointing \
  --seed="0" \
  --use_8bit_adam \
"""



# run command
print({train_cmd})
if TRAIN_MODEL:

  !{train_cmd}
else:
  print("Skipping training. Set TRAIN_MODEL to train model.")

"""## Upload to Hub

"""

if TRAIN_MODEL:
  # Upload model to hub
  from huggingface_hub import create_repo, upload_folder

  # HF WRITE token
  from huggingface_hub import notebook_login
  notebook_login()

  # create a repo on the huggingface hub
  create_repo(MODEL_NAME, exist_ok=True)

  # upload the model folder
  upload_folder(
      folder_path=output_dir,
      repo_id=MODEL_NAME,
  )

"""# Inference

Create Inference Pipeline
"""

from diffusers import DiffusionPipeline
import torch

# Load model to pipeline
if TRAIN_MODEL:
  pipeline = DiffusionPipeline.from_pretrained(
      output_dir,
      torch_dtype=torch.float16,
      use_safetensors=True).to("cuda")
else:
  pipeline = DiffusionPipeline.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    use_safetensors=True).to("cuda")

image = pipeline(TEST_PROMPT, num_inference_steps=50, guidance_scale=7.5).images[0]
i=0
# create output dir if not exist
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
image.save(os.path.join(output_dir, f"generated_image_{i}.png"))
image

# some more inference trials
NEW_PROMPT = "brad pitt holding a sks bowl"
i += 1
# manual seed
generator = torch.Generator("cuda").manual_seed(42)

image = pipeline(NEW_PROMPT, num_inference_steps=150, guidance_scale=7.5, generator=generator).images[0]
image.save(os.path.join(output_dir, f"42_GS175_S150_{NEW_PROMPT}_{i}.png"))
image

#copy output folder to drive
from google.colab import drive
drive.mount('/content/drive')
# copy out folder to drive in python
shutil.copytree(output_dir, os.path.join('/content/drive/MyDrive/', DS_NAME), dirs_exist_ok=True)

"""# DDIM Scheduler for Inference


"""

from diffusers import DDIMScheduler
default_scheduler = pipeline.scheduler
print(default_scheduler)

ddim_scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear", clip_sample=False, set_alpha_to_one=False)
print(ddim_scheduler)

# some more inference trials with new scheduler
#NEW_PROMPT = "photo of dog in sks style"
i += 1

for steps in [50,100,150,200]:
  for gs in [.5,1, 3, 7.5, 15]:
    image = pipeline(NEW_PROMPT, num_inference_steps=steps, guidance_scale=gs, generator=generator, scheduler=ddim_scheduler).images[0]
    image.save(os.path.join(output_dir, f"DDIM_GS{str(gs)}_S{steps}_{NEW_PROMPT}_{i}.png"))
    image = pipeline(NEW_PROMPT, num_inference_steps=steps, guidance_scale=gs, generator=generator, scheduler=default_scheduler).images[0]
    image.save(os.path.join(output_dir, f"PNDMS_GS{str(gs)}_S{steps}_{NEW_PROMPT}_{i}.png"))

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

# Assuming 'output_dir' is already defined as in your code
image_files = [f for f in os.listdir(output_dir) if f.startswith('PNDMS')]
image_files.sort()

# Adjust grid dimensions as needed
num_cols = 4
num_rows = 5

fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))
fig.suptitle(image_files[0].split('_')[-2], fontsize=16)

for i, file in enumerate(image_files):
    row = i // num_cols
    col = i % num_cols
    img = mpimg.imread(os.path.join(output_dir, file))
    axes[row, col].imshow(img)
    axes[row, col].set_title(file.split('_')[0:3])
    axes[row, col].axis('off')

# Hide any unused subplots
for i in range(len(image_files), num_rows * num_cols):
    row = i // num_cols
    col = i % num_cols
    axes[row, col].axis('off')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

image_files = [f for f in os.listdir(output_dir) if f.startswith('DDIM')]
image_files.sort()

# Adjust grid dimensions as needed
num_cols = 4
num_rows = 5

fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))
fig.suptitle(image_files[0].split('_')[-2], fontsize=16)

for i, file in enumerate(image_files):
    row = i // num_cols
    col = i % num_cols
    img = mpimg.imread(os.path.join(output_dir, file))
    axes[row, col].imshow(img)
    axes[row, col].set_title(file.split('_')[0:3])
    axes[row, col].axis('off')

# Hide any unused subplots
for i in range(len(image_files), num_rows * num_cols):
    row = i // num_cols
    col = i % num_cols
    axes[row, col].axis('off')

plt.tight_layout()
plt.show()

